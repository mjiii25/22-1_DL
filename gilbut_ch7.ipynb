{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPNCT3thOJWUmKM33VHPNKP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjiii25/22-1_DLAI/blob/main/gilbut_ch7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 7"
      ],
      "metadata": {
        "id": "JECquUwO4CIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functional API"
      ],
      "metadata": {
        "id": "LArM70nI5L7z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xb8bdMN4A6b"
      },
      "outputs": [],
      "source": [
        "from keras import Input, layers\n",
        "\n",
        "input_tensor = Input(shape = (32,))\n",
        "dense = layers.Dense(32, activation = 'relu')\n",
        "\n",
        "output_tensor = dense(input_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential model vs Functinal API"
      ],
      "metadata": {
        "id": "vKmgeMWE70_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "\n",
        "## Sequential model\n",
        "seq_model = Sequential()\n",
        "seq_model.add(layers.Dense(32, activation = 'relu', input_shape = (64,)))\n",
        "seq_model.add(layers.Dense(32, activation = 'relu'))\n",
        "seq_model.add(layers.Dense(10, activation = 'softmax'))\n",
        "\n",
        "\n",
        "## Functional API\n",
        "input_tensor = Input(shape = (64,))\n",
        "x = layers.Dense(32, activation = 'relu')(input_tensor)\n",
        "x = layers.Dense(32, activation = 'relu')(x)\n",
        "output_tensor = layers.Dense(10, activation = 'softmax')(x)\n",
        "\n",
        "model = Model(input_tensor, output_tensor)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juCX5Dai5blW",
        "outputId": "2a4ab546-2d64-49a7-c968-954f75a4cce7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64)]              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,466\n",
            "Trainable params: 3,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'rmsprop',\n",
        "              loss = 'categorical_crossentropy')\n",
        "\n",
        "import numpy as np\n",
        "x_train = np.random.random((1000,64))\n",
        "y_train = np.random.random((1000,10))\n",
        "\n",
        "model.fit(x_train, y_train, epochs = 10, batch_size = 128)\n",
        "score = model.evaluate(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl8nMDBn6Qqf",
        "outputId": "e830a44d-ee95-4b0b-c3ab-66f4b5a618b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 2s 4ms/step - loss: 12.0645\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.5432\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 13.5834\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 15.5696\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 18.5459\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 22.3297\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 26.4857\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 30.5986\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 34.3478\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 38.3049\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 40.2100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-input model"
      ],
      "metadata": {
        "id": "yXmeuQan7XbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "\n",
        "\n",
        "text_vocabulary_size = 10000\n",
        "question_vocabulary_size = 10000\n",
        "answer_vocabulary_size = 500\n",
        "\n",
        "text_input = Input(shape = (None,), dtype = 'int32', name = 'text')\n",
        "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
        "encoded_text = layers.LSTM(32)(embedded_text)\n",
        "\n",
        "question_input = Input(shape = (None,), dtype = 'int32', name = 'question')\n",
        "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
        "encoded_question = layers.LSTM(16)(embedded_question)\n",
        "\n",
        "concatenated = layers.concatenate([encoded_text, encoded_question], axis = -1)    # connect encoded text and question\n",
        "\n",
        "answer = layers.Dense(answer_vocabulary_size, activation = 'softmax')(concatenated)\n",
        "\n",
        "model = Model([text_input, question_input], answer)\n",
        "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['acc'])"
      ],
      "metadata": {
        "id": "tTotsnYK7NwY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "num_samples = 1000\n",
        "max_length = 100\n",
        "\n",
        "text = np.random.randint(1, text_vocabulary_size, size = (num_samples, max_length))\n",
        "question = np.random.randint(1, question_vocaulary_size, size = (num_samples, max_length))\n",
        "\n",
        "answers = np.random.randint(0, answer_vocabulary_size, size = num_samples)\n",
        "answers = to_categorical(answers)                                                 # one-hot encoded\n",
        "\n",
        "model.fit([text, question], answers, epochs = 10, batch_size = 128)\n",
        "model.fit({'text' : text, 'question' : question}, answers, epochs = 10, batch_size = 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "meJkn4E3-K0N",
        "outputId": "89f5561d-d0bb-44f7-8ceb-63a0e522ae81"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2bdf093908de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "multi-output model"
      ],
      "metadata": {
        "id": "msSSKT4jFT7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "vocabulary_size = 50000\n",
        "num_income_groups = 10"
      ],
      "metadata": {
        "id": "A8PknyF3FJ4z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}